{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing & Document Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn.metrics.pairwise import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for d in range(1400):\n",
    "    f = open(\"./d/\"+str(d+1)+\".txt\")\n",
    "    text = f.read()\n",
    "    corpus.append(text)\n",
    "for q in range(225):\n",
    "    f = open(\"./q/\"+str(q+1)+\".txt\")\n",
    "    text = f.read()\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare vectorizers (binary, term_frequency, tf-idf) and compute cosine and euclidean similarity between given queries and documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init vectorizers\n",
    "vectorizer_binary = CountVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict',\n",
    "                                   stop_words=u'english', binary=True)\n",
    "\n",
    "vectorizer_tf = CountVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict',\n",
    "                                   stop_words=u'english', binary=False)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(input=u'content', encoding=u'utf-8', decode_error=u'strict',\n",
    "                                   stop_words=u'english', use_idf=True)\n",
    " \n",
    "# prepare matrices\n",
    "term_matrix_binary = vectorizer_binary.fit_transform(corpus)\n",
    "term_matrix_tf = vectorizer_tf.fit_transform(corpus)\n",
    "term_matrix_tfidf = vectorizer_tfidf.fit_transform(corpus)\n",
    "\n",
    " \n",
    "# compute similarity between each query and all docs\n",
    "cos_sim_binary = np.array(cosine_similarity(term_matrix_binary[len(corpus)-225:], \n",
    "                             term_matrix_binary[0:len(corpus)-225]))\n",
    "\n",
    "cos_sim_tf = np.array(cosine_similarity(term_matrix_tf[len(corpus)-225:], \n",
    "                             term_matrix_tf[0:len(corpus)-225]))\n",
    "\n",
    "cos_sim_tfidf = np.array(cosine_similarity(term_matrix_tfidf[len(corpus)-225:], \n",
    "                             term_matrix_tfidf[0:len(corpus)-225]))\n",
    "\n",
    "euc_sim_binary = np.array(euclidean_distances(term_matrix_binary[len(corpus)-225:], \n",
    "                             term_matrix_binary[0:len(corpus)-225]))\n",
    "\n",
    "euc_sim_tf = np.array(euclidean_distances(term_matrix_tf[len(corpus)-225:], \n",
    "                             term_matrix_tf[0:len(corpus)-225]))\n",
    "\n",
    "euc_sim_tfidf = np.array(euclidean_distances(term_matrix_tfidf[len(corpus)-225:], \n",
    "                             term_matrix_tfidf[0:len(corpus)-225]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds how many documents should be returned to maximize F-measure for each similarity.\n",
    "These thresholds are experimentally found for given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_sim_binary_threshold = 17\n",
    "cos_sim_tf_threshold = 15\n",
    "cos_sim_tfidf_threshold = 14\n",
    "\n",
    "euc_sim_binary_threshold = 16\n",
    "euc_sim_tf_threshold = 19\n",
    "euc_sim_tfidf_threshold = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for getting precision, recall and F-measure.\n",
    "Inputs: (Found documents for given query, Relative documents for given query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prec_rec_F_meas(best_docs, relative_docs):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for k in range(len(best_docs)):\n",
    "        if best_docs[k] in relative_docs:\n",
    "            tp = tp + 1\n",
    "    fn = len(relative_docs)-tp\n",
    "    fp = len(best_docs) - tp\n",
    "    tn = 1400 - len(best_docs) - fn\n",
    "    \n",
    "    try:\n",
    "        prec = tp/float((tp+fp))\n",
    "        rec = tp/float((tp+fn))\n",
    "        F_measure = 2*(prec*rec)/(prec+rec)\n",
    "    except ZeroDivisionError:\n",
    "        prec = 0\n",
    "        rec = 0\n",
    "        F_measure = 0\n",
    "    \n",
    "    result = {}\n",
    "    result[\"prec\"] = prec\n",
    "    result[\"rec\"] = rec\n",
    "    result[\"F_meas\"] = F_measure\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute precision, recall, F-measure for every given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(225):\n",
    "    f = open(\"./r/\"+str(i+1)+\".txt\")\n",
    "    text = f.read() \n",
    "    relative_docs = text.split('\\n')[:-1]\n",
    "    relative_docs = [int(j) for j in relative_docs]\n",
    "    \n",
    "    cos_sim_bin_best_docs = (cos_sim_binary[i].argsort()[:][::-1]+1)[:cos_sim_binary_threshold]\n",
    "    cos_sim_tf_best_docs = (cos_sim_tf[i].argsort()[:][::-1]+1)[:cos_sim_tf_threshold]\n",
    "    cos_sim_tfidf_best_docs = (cos_sim_tfidf[i].argsort()[:][::-1]+1)[:cos_sim_tfidf_threshold]\n",
    "    \n",
    "    euc_sim_bin_best_docs = (euc_sim_binary[i].argsort()[:][::-1]+1)[:euc_sim_binary_threshold]\n",
    "    euc_sim_tf_best_docs = (euc_sim_tf[i].argsort()[:][::-1]+1)[:euc_sim_tf_threshold]\n",
    "    euc_sim_tfidf_best_docs = (euc_sim_tfidf[i].argsort()[:][::-1]+1)[:euc_sim_tfidf_threshold]\n",
    "    \n",
    "    tmp_res = []\n",
    "    \n",
    "    tmp_res.append(get_prec_rec_F_meas(cos_sim_bin_best_docs, relative_docs))\n",
    "    tmp_res.append(get_prec_rec_F_meas(cos_sim_tf_best_docs, relative_docs))\n",
    "    tmp_res.append(get_prec_rec_F_meas(cos_sim_tfidf_best_docs, relative_docs))\n",
    "    \n",
    "    tmp_res.append(get_prec_rec_F_meas(euc_sim_bin_best_docs, relative_docs))\n",
    "    tmp_res.append(get_prec_rec_F_meas(euc_sim_tf_best_docs, relative_docs))\n",
    "    tmp_res.append(get_prec_rec_F_meas(euc_sim_tfidf_best_docs, relative_docs))\n",
    "    \n",
    "    results.append(np.array([\n",
    "        tmp_res[0][\"F_meas\"],\n",
    "        tmp_res[1][\"F_meas\"],\n",
    "        tmp_res[2][\"F_meas\"],\n",
    "        tmp_res[3][\"F_meas\"],\n",
    "        tmp_res[4][\"F_meas\"],\n",
    "        tmp_res[5][\"F_meas\"],\n",
    "        tmp_res[0][\"prec\"],\n",
    "        tmp_res[1][\"prec\"],\n",
    "        tmp_res[2][\"prec\"],\n",
    "        tmp_res[3][\"prec\"],\n",
    "        tmp_res[4][\"prec\"],\n",
    "        tmp_res[5][\"prec\"],\n",
    "        tmp_res[0][\"rec\"],\n",
    "        tmp_res[1][\"rec\"],\n",
    "        tmp_res[2][\"rec\"],\n",
    "        tmp_res[3][\"rec\"],\n",
    "        tmp_res[4][\"rec\"],\n",
    "        tmp_res[5][\"rec\"]\n",
    "    ]))\n",
    "    \n",
    "    ''' Print methods sorted by F-measure\n",
    "    array = np.array([\n",
    "    tmp_res[0][\"F_meas\"],\n",
    "    tmp_res[1][\"F_meas\"],\n",
    "    tmp_res[2][\"F_meas\"],\n",
    "    tmp_res[3][\"F_meas\"],\n",
    "    tmp_res[4][\"F_meas\"],\n",
    "    tmp_res[5][\"F_meas\"]\n",
    "    ])\n",
    "    print(array.argsort()[::-1])\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    print(cos_sim_bin_best_docs)\n",
    "    print(euc_sim_bin_best_docs)\n",
    "    print(cos_sim_tf_best_docs)\n",
    "    print(euc_sim_tf_best_docs)\n",
    "    print(cos_sim_tf_best_docs)\n",
    "    print(euc_sim_tf_best_docs)\n",
    "    print()\n",
    "    '''\n",
    "\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"cos_sim_binary.csv\", cos_sim_binary, delimiter=\",\")\n",
    "np.savetxt(\"cos_sim_tf.csv\", cos_sim_tf, delimiter=\",\")\n",
    "np.savetxt(\"cos_sim_tfidf.csv\", cos_sim_tfidf, delimiter=\",\")\n",
    "np.savetxt(\"euc_sim_binary.csv\", euc_sim_binary, delimiter=\",\")\n",
    "np.savetxt(\"euc_sim_tf.csv\", euc_sim_tf, delimiter=\",\")\n",
    "np.savetxt(\"euc_sim_tfidf.csv\", euc_sim_tfidf, delimiter=\",\")\n",
    "\n",
    "np.savetxt(\"results.csv\", results, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
